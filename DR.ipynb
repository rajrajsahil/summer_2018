{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import data_util\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (10000, 32, 32, 3)\n",
      "Training label shape (10000,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "DR_dataset_dir = 'diabetic_dataset'\n",
    "X_train,Y_train = data_util.load_dr_dataset(DR_dataset_dir)\n",
    "print('Training data shape',X_train.shape)\n",
    "print('Training label shape',Y_train.shape)\n",
    "batch_size,height,width,channels=X_train.shape\n",
    "filters = np.random.rand(3,3,channels,3)*0.001\n",
    "X_train = X_train - np.mean(X_train,axis = 0)\n",
    "X_train = X_train.astype(np.float32)\n",
    "print(type(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_filter_1 = tf.Variable(np.array(filters),dtype=np.float32,name='conv_filter_1')\n",
    "conv_filter_2 = tf.Variable(np.array(filters),dtype=np.float32,name='conv_filter_2')\n",
    "num_output_class = 10\n",
    "X = tf.placeholder(tf.float32)\n",
    "convolution_1 = tf.nn.conv2d(X,conv_filter_1,strides=[1,1,1,1],padding='SAME',name='convolution_1')\n",
    "# with tf.Session() as sess:\n",
    "#     output_1 = sess.run(convolution_1,{X:X_train[0:1,:,:,:]})\n",
    "# print(output_1.shape)\n",
    "# plt.imshow(output_1[0,:,:,0].astype('uint8'))\n",
    "# plt.show()\n",
    "output_1_pool = tf.nn.max_pool(convolution_1,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"VALID\",name='output_1_pool')\n",
    "# with tf.Session() as sess:\n",
    "#     output_1_pool = sess.run(max_pool,{X:output_1})\n",
    "# print(output_1_pool.shape)\n",
    "# plt.imshow(output_1_pool[0,:,:,0].astype('uint8'))\n",
    "# plt.show()\n",
    "\n",
    "convolution_2 = tf.nn.conv2d(output_1_pool,conv_filter_2,strides=[1,1,1,1],padding=\"SAME\",name='convolution_2')\n",
    "output_2 = tf.contrib.layers.flatten(convolution_2)\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "#     output_2 = sess.run(convolution_2,{X:X_train[0:1,:,:,:]})\n",
    "\n",
    "    \n",
    "# output_2 = output_2.reshape(output_2.shape[0],-1)\n",
    "# print(output_2.shape)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     output_2 = sess.run(convolution_2,{X:output_1_pool})\n",
    "# print(output_2.shape)\n",
    "# plt.imshow(output_2[0,:,:,0].astype('uint8'))\n",
    "# plt.show()\n",
    "\n",
    "# shapes = np.array(convolution_2).shape\n",
    "# output_2 = np.array(convolution_2).reshape(shapes[0],-1)\n",
    "weight = tf.Variable(np.random.randn(768,num_output_class),dtype=np.float32,name='full_conv_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2255578\n",
      "2.091898\n",
      "1.8487083\n",
      "1.443548\n",
      "0.9361595\n",
      "0.52025104\n",
      "0.2899613\n",
      "0.17861073\n",
      "0.12154391\n",
      "0.08915122\n",
      "time-delay: 3.5497779846191406\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "final_output = tf.reshape(tf.nn.relu(tf.matmul(output_2,weight)),(10,),name='final_output')\n",
    "# print(final_output)\n",
    "# print(Y_train[0])\n",
    "\n",
    "softmax = tf.nn.softmax(final_output)\n",
    "softmax_loss = - tf.log(softmax)[Y_train[0]]\n",
    "learning_rate = 5e-6\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(softmax_loss)\n",
    "# gradient = tf.reshape(tf.gradients(softmax_loss,weight),(768,10))\n",
    "\n",
    "# cross_entropy_gradient = (softmax_loss-1) * final_output\n",
    "\n",
    "# weight_update = tf.assign(weight, weight - learning_rate * gradient)\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "writer = tf.summary.FileWriter('./graphs/linear_reg', tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "#     saver.restore(sess,\"/tmp/my_model_final.ckpt\")\n",
    "    sess.run(init)\n",
    "    for i in range(100):\n",
    "        sess.run(train,{X:X_train[0:1,:,:,:]})\n",
    "        if i % 10 == 0:\n",
    "            save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
    "            print(sess.run(softmax_loss,{X:X_train[0:1,:,:,:]}))\n",
    "#     softmax_loss = - np.log(sess.run(softmax))[Y_train[0]]\n",
    "toc = time.time()\n",
    "print('time-delay:',toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
